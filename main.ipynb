{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-10-09T13:14:43.041446Z","iopub.execute_input":"2021-10-09T13:14:43.041804Z","iopub.status.idle":"2021-10-09T13:14:43.049527Z","shell.execute_reply.started":"2021-10-09T13:14:43.041768Z","shell.execute_reply":"2021-10-09T13:14:43.048837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2021-10-09T13:14:44.806876Z","iopub.execute_input":"2021-10-09T13:14:44.807199Z","iopub.status.idle":"2021-10-09T13:14:45.483438Z","shell.execute_reply.started":"2021-10-09T13:14:44.807162Z","shell.execute_reply":"2021-10-09T13:14:45.482635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data.dataset import Dataset\nimport torch.nn.functional as F\nimport albumentations as albu\n\nimport glob\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport sklearn\n#from efficientnet_pytorch import EfficientNet\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\n#modelName = 'efficientnet-b4'\n#modelSize = EfficientNet.get_image_size(modelName)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T14:25:33.495803Z","iopub.execute_input":"2021-10-09T14:25:33.496831Z","iopub.status.idle":"2021-10-09T14:25:37.514529Z","shell.execute_reply.started":"2021-10-09T14:25:33.496686Z","shell.execute_reply":"2021-10-09T14:25:37.513549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport glob\n\ndata = glob.glob(\"../input/deweight-huaweimetal/de_weight/de-weight-train/*/*.jpg\")\n\nname2class = {}\nname = 6.5\nfor i in range(14):\n    name2class[str(name)] = i\n    name += 0.5\n    \nfileName = []\nlabel = []\nclassName = []\nfor fn in data:\n    fileName.append(fn.split(\"/\")[-1].strip(\".jpg\"))\n    className.append(fn.split(\"/\")[-2])\n    label.append(name2class[fn.split(\"/\")[-2]])\nd = {\"fileName\":fileName, \"Class\":label,\"ClassName\":className}\ndf = pd.DataFrame(d)\n\ndf.to_csv('classes_de.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!unzip -q /home/ma-user/work/data.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"./classes_de.csv\")\n#df = pd.read_csv(\"/home/ma-user/work/classes.csv\")\nfnames = df[\"fileName\"].tolist()\nclassNames = df[\"ClassName\"].tolist()\nclasses = df[\"Class\"].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Dataset***","metadata":{}},{"cell_type":"markdown","source":"预处理： - crop正方形之后resize (1376,1104) - > (1104,1104) - > (224,224)\n        - 黑白图片normalize mean 0.5 标准差 0.5(?)\n\nAug:   见dataset.tfms \n\n训练黑白和彩色模型时需要改dataset相关部分。\n现在dataset为加载彩色与黑白图片后 cat到一起 （batch_size，channel = 6，224,224）","metadata":{}},{"cell_type":"code","source":"class MetalDataset(Dataset):\n    def __init__(self, fileNames, labels, training = True, preproccess = False):\n        #self.img_path = \"/home/ma-user/work/train\"\n        self.training = training\n        crop_size = 1104\n        if training:\n            self.tfms = albu.Compose([\n                                        albu.CenterCrop(1104,1104),\n                                        albu.Resize(224, 224), \n                                        albu.HorizontalFlip(p=0.5),\n                                        albu.VerticalFlip(p=0.5),\n                                        albu.Transpose(p=0.2),\n                                        albu.ElasticTransform(alpha=2000,sigma=100,alpha_affine=1,p=0.2), #一般来说，alpha越小，sigma越大，产生的偏差越小，和原图越接近\n                                        albu.MotionBlur(blur_limit=5,p=0.1),\n                                        albu.Rotate(limit=(-180,180),p = 0.1, border_mode=cv2.BORDER_WRAP)],\n                         additional_targets={\n                                                'image': 'image',\n                                                'gray': 'image',}\n                        )      \n        else:\n            self.tfms = albu.Compose([\n                                        albu.CenterCrop(1104,1104),\n                                        albu.Resize(224, 224), \n                                                           ], \n                            additional_targets={\n                                        'image': 'image',\n                                        'gray': 'image',}\n            )        \n            \n        self.fileNames = fileNames\n        self.labels = labels\n        self.name2class = {}\n        name = 6.5\n        for i in range(14):\n            self.name2class[name] = torch.tensor(i)\n            name += 0.5\n            \n    def __getitem__(self, index):\n        img = cv2.imread(\"../input/deweight-huaweimetal/de_weight/de-weight-train/{:}/{:}.jpg\".format(self.labels[index],self.fileNames[index]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        gray = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2RGB)\n        transformed = self.tfms(image=img, gray=gray)\n        #transformed = self.tfms(image = img)\n        img = transformed[\"image\"]\n        gray = transformed[\"gray\"]\n        \n        img = Image.fromarray(img)   \n        gray = Image.fromarray(gray) \n        img = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])])(img)\n        gray = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                 std=[0.5, 0.5, 0.5])])(gray)\n        img = torch.cat((img,gray),0)\n        return img, self.name2class[self.labels[index]]\n    \n    def __len__(self):\n        return len(self.fileNames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MetalDataset(fnames, classNames)[0][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Train & Eval one epoche***","metadata":{}},{"cell_type":"code","source":"def trainOneEpoche(model, loader, criterion, optimizer,reg = False):\n    model.train()\n    runningLoss = 0\n    i = 0\n    y_all = []\n    outputs_all = [] # For Acc\n    for imgs, labels in tqdm(loader):\n        imgs = imgs.to(device)\n        labels= labels.to(device)\n        optimizer.zero_grad()\n        \n        output = model(imgs).squeeze()\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        runningLoss += loss\n        i+=1\n        outputs_all.extend(output.cpu().detach().numpy())\n        y_all.extend(labels.cpu().detach().numpy())\n\n    acc = computeAccuracy(outputs_all, y_all, reg = reg)\n    return runningLoss/i, acc\n\ndef evalOneEpoche(model, loader, criterion, reg = False):\n    model.eval()\n    runningLoss = 0\n    i = 0\n    \n    y_all = []\n    outputs_all = [] # For AuC\n    \n    with torch.no_grad():\n        \n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            labels= labels.to(device)\n            output = model(imgs).squeeze()\n            \n            loss = criterion(output, labels)\n            runningLoss += loss\n            i+=1\n            outputs_all.extend(output.cpu().detach().numpy())\n            y_all.extend(labels.cpu().detach().numpy())\n\n        acc = computeAccuracy(outputs_all, y_all, reg = reg)\n        return runningLoss/i, acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Custom Loss function***","metadata":{}},{"cell_type":"code","source":"class MultiFocalLoss(nn.Module):\n    \"\"\"\n    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n        Focal_Loss= -1*alpha*(1-pt)^gamma*log(pt)\n    :param num_class:\n    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n                    focus on hard misclassified example\n    :param smooth: (float,double) smooth value when cross entropy\n    :param balance_index: (int) balance class index, should be specific when alpha is float\n    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n    \"\"\"\n\n    def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True):\n        super(MultiFocalLoss, self).__init__()\n        self.num_class = num_class\n        self.alpha = alpha\n        self.gamma = gamma\n        self.smooth = smooth\n        self.size_average = size_average\n\n        if self.alpha is None:\n            self.alpha = torch.ones(self.num_class, 1)\n        elif isinstance(self.alpha, (list, np.ndarray)):\n            assert len(self.alpha) == self.num_class\n            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n            self.alpha = self.alpha / self.alpha.sum()\n        elif isinstance(self.alpha, float):\n            alpha = torch.ones(self.num_class, 1)\n            alpha = alpha * (1 - self.alpha)\n            alpha[balance_index] = self.alpha\n            self.alpha = alpha\n        else:\n            raise TypeError('Not support alpha type')\n\n        if self.smooth is not None:\n            if self.smooth < 0 or self.smooth > 1.0:\n                raise ValueError('smooth value should be in [0,1]')\n\n    def forward(self, input, target):\n        logit = F.softmax(input, dim=1)\n\n        if logit.dim() > 2:\n            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n            logit = logit.view(logit.size(0), logit.size(1), -1)\n            logit = logit.permute(0, 2, 1).contiguous()\n            logit = logit.view(-1, logit.size(-1))\n        target = target.view(-1, 1)\n\n        # N = input.size(0)\n        # alpha = torch.ones(N, self.num_class)\n        # alpha = alpha * (1 - self.alpha)\n        # alpha = alpha.scatter_(1, target.long(), self.alpha)\n        epsilon = 1e-10\n        alpha = self.alpha\n        if alpha.device != input.device:\n            alpha = alpha.to(input.device)\n\n        idx = target.cpu().long()\n        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n        if one_hot_key.device != logit.device:\n            one_hot_key = one_hot_key.to(logit.device)\n\n        if self.smooth:\n            one_hot_key = torch.clamp(\n                one_hot_key, self.smooth, 1.0 - self.smooth)\n        pt = (one_hot_key * logit).sum(1) + epsilon\n        logpt = pt.log()\n\n        gamma = self.gamma\n\n        alpha = alpha[idx]\n        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n\n        if self.size_average:\n            loss = loss.mean()\n        else:\n            loss = loss.sum()\n        return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BetterLoss 模拟regression，把各个相似类的信息互通 （单纯训练regression task结果不如分类好 ~-2.0% acc）","metadata":{}},{"cell_type":"code","source":"class betterLoss(nn.Module):\n    ## criterion for True label, CE loss for fuzzy label\n    def __init__(self, criterion =  nn.CrossEntropyLoss(), beta = 0.1):\n        super(betterLoss, self).__init__()\n        self.criterion = criterion\n        self.beta = beta\n    def forward(self, output, labels):\n        lossTrue = self.criterion(output,labels) * (1/(1+self.beta))\n        labels_plus = labels.clone()\n        labels_minus = labels.clone()\n        for i in range(len(labels)):\n            if labels[i] > 0:\n                labels_minus[i]-=1\n            if labels[i]< 13:\n                labels_plus[i]+=1\n\n        lossFuzzy = (self.beta/(1+self.beta))*(self.criterion(output,labels_plus) + self.criterion(output,labels_minus))\n        \n        return lossTrue + lossFuzzy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Accuracy***","metadata":{}},{"cell_type":"code","source":"def computeAccuracy(output,labels,reg = False):\n    alpha = 0.4\n    beta = 0.6\n    acc_0_classes = [1]*14\n    acc_0_5_classes = [1]*14\n    class_num = [1]*14\n    with torch.no_grad():\n        score_0 = 0\n        score_0_5 = 0\n        output = torch.tensor(output)\n        if reg:\n            pred = torch.round(output) #For regression task\n        else:\n            _, pred = output.topk(1)\n        score = 0\n        for o,l in zip(pred,labels):\n            l = int(l)\n            o = max(0,min(13,o))\n            class_num[l] += 1\n            if o == l:\n                score += 1\n                score_0 +=1\n                score_0_5 += 1\n                acc_0_classes[l] += 1\n            elif o == l+1 or o == l-1:\n                score += beta\n                score_0_5 += 1\n                acc_0_5_classes[l] += 1\n        acc_0_classes = [x/y for x,y in zip(acc_0_classes,class_num)]\n        acc_0_5_classes = [x/y for x,y in zip(acc_0_5_classes,class_num)]\n        \n        return score/len(labels), score_0/len(labels), score_0_5/len(labels), acc_0_classes, acc_0_5_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"将两个模型的结果softmax归一后 50%50%相加 我训练了黑白+彩色模型","metadata":{}},{"cell_type":"code","source":"class mergeModel(nn.Module):\n    def __init__(self, model1=None, model2=None):\n        super(mergeModel, self).__init__()\n        if model1:\n            self.model1 = model1\n        else:\n            model = torchvision.models.__dict__['resnet152'](pretrained  = False)\n            channel_in = model.fc.in_features\n            model.fc = nn.Linear(channel_in, 14) #Classificiation\n            self.model1 = model\n        if model2:\n            self.model2 = model2\n        else:\n            model = torchvision.models.__dict__['resnet152'](pretrained  = False)\n            channel_in = model.fc.in_features\n            model.fc = nn.Linear(channel_in, 14) #Classificiation\n            self.model2 = model\n            \n        self.softmax = nn.Softmax(dim = 1)\n        \n    def forward(self, img):\n        o1 = self.model1(img[:,:3,:,:])\n        o2 = self.model2(img[:,3:,:,:])\n        o1 = self.softmax(o1)\n        o2 = self.softmax(o2)\n        out = 0.5*o1+0.5*o2\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-09T14:34:35.488286Z","iopub.execute_input":"2021-10-09T14:34:35.489311Z","iopub.status.idle":"2021-10-09T14:34:35.498933Z","shell.execute_reply.started":"2021-10-09T14:34:35.489272Z","shell.execute_reply":"2021-10-09T14:34:35.498106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Params***","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ninitial_LR = 2e-4\ngamma = 0.8 #Exp scheduler gamma\n\nepoches = 70\nT_0 = 10\nT_mult = 2\nn_splits = 10\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nclass_weights= sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(classes),np.array(classes))\n#class_weights=torch.tensor(class_weights,dtype=torch.float).to(device)\n\n#criterion = nn.CrossEntropyLoss(class_weights)\ncriterion = MultiFocalLoss(14, alpha=class_weights, gamma=5)\nprint(class_weights)\ncriterion = betterLoss(criterion,beta = 0.1)\n#criterion = nn.MSELoss()\n#eval_crit = nn.MSELoss()\neval_crit = nn.CrossEntropyLoss()\nuse_cv = True\npreproc = True\nreg = False\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state = 21)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodelRGB = torch.load(\"../input/metalmodels/0.8501278772378519_trained_resnet152.pt\", map_location=device)\nmodelGRAY = torch.load(\"../input/metalmodels/0.8629156010230179_trained_effnet.pt\", map_location=device)\nmodel = mergeModel(modelRGB, modelGRAY)\n\ntorch.save(model,\"mergedModel.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T13:56:53.102492Z","iopub.execute_input":"2021-10-09T13:56:53.10279Z","iopub.status.idle":"2021-10-09T13:56:55.301454Z","shell.execute_reply.started":"2021-10-09T13:56:53.102761Z","shell.execute_reply":"2021-10-09T13:56:55.30039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = torch.load(\"../input/metaltestmodels/mergedModel.pt\", map_location=device)\ntorch.save(model.state_dict(),\"mergedModel.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T14:28:18.263917Z","iopub.execute_input":"2021-10-09T14:28:18.264279Z","iopub.status.idle":"2021-10-09T14:28:26.658699Z","shell.execute_reply.started":"2021-10-09T14:28:18.264245Z","shell.execute_reply":"2021-10-09T14:28:26.657434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = mergeModel()\nmodel.load_state_dict(torch.load(\"mergedModel.pt\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-09T14:34:39.48537Z","iopub.execute_input":"2021-10-09T14:34:39.486327Z","iopub.status.idle":"2021-10-09T14:34:43.006633Z","shell.execute_reply.started":"2021-10-09T14:34:39.486276Z","shell.execute_reply":"2021-10-09T14:34:43.005696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Do Cross Validation***","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i_train, i_val in skf.split(fnames, classes):\n    max_acc = 0.84\n    trainDataset = MetalDataset([fnames[i] for i in i_train],[classNames[i] for i in i_train],training = True)\n    valDataset = MetalDataset([fnames[i] for i in i_val],[classNames[i] for i in i_val],training = False)\n    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size = batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    valLoader = torch.utils.data.DataLoader(valDataset, batch_size = batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    \n    #此处为不同模型\n    model = torchvision.models.__dict__['resnet152'](pretrained  = True)\n    channel_in = model.fc.in_features\n    model.fc = nn.Linear(channel_in, 14) #Classificiation\n    #model.fc = nn.Linear(channel_in, 1) #Regression\n    #modelRGB = torch.load(\"../input/metalmodels/0.8501278772378519_trained_resnet152.pt\")\n    #modelGRAY = torch.load(\"../input/metalmodels/0.8629156010230179_trained_effnet.pt\")\n    model = mergeModel(modelRGB, modelGRAY)\n    #model = EfficientNet.from_pretrained(modelName)\n    #channel_in = model._fc.in_features\n    #model._fc = nn.Linear(channel_in, 14)\n    model.to(device)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=initial_LR)\n    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # Learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult=T_mult, eta_min=initial_LR*0.1)\n    \n    TrainingLoss = []\n    ValLoss = []\n    ValAcc = []\n    ValAcc_0 = []\n    ValAcc_0_5 = []\n\n    TrainingLoss.append([])\n    ValLoss.append([])\n    ValAcc.append([])\n    ValAcc_0.append([])\n    ValAcc_0_5.append([])\n\n    for e in range(epoches):\n            #runningtrainLoss,(train_acc,train_acc_0,train_acc_0_5,train_acc_0_classes, train_acc_0_5_classes) = trainOneEpoche(model, trainLoader, criterion, optimizer,reg=reg)\n            runningvalLoss, (acc,acc_0,acc_0_5,acc_0_classes, acc_0_5_classes) = evalOneEpoche(model, valLoader, eval_crit,reg=reg)\n            print(\"Current LR: {:}\".format(scheduler.get_last_lr()))\n            #print(\"epoche {:} TrainingLoss: {:}, Accuracy: {:}, AccuracyTrue: {:}, Accuracy+-0.5: {:}\".format(e,round(float(runningtrainLoss),4), round(float(train_acc),4), round(float(train_acc_0),4), round(float(train_acc_0_5),4)))\n            print(\"--------- EvalLoss: {:}, Accuracy: {:}, AccuracyTrue: {:}, Accuracy+-0.5: {:}\".format(round(float(runningvalLoss),4),round(float(acc),4),round(float(acc_0),4),round(float(acc_0_5),4)))\n            print(acc_0_classes)\n            TrainingLoss[-1].append(runningtrainLoss)\n            ValLoss[-1].append(runningvalLoss)\n            ValAcc[-1].append(acc)\n            ValAcc_0[-1].append(acc_0)\n            ValAcc_0_5[-1].append(acc_0_5)\n            if acc > max_acc:\n                max_acc = acc\n                torch.save(model, \"{:}_trained_effnet.pt\".format(acc))\n            scheduler.step()\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Evaluate models***","metadata":{}},{"cell_type":"code","source":"models = glob.glob(\"./*.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,(x,y,z,a,b) in enumerate(zip(TrainingLoss[0], ValLoss[0], ValAcc[0],ValAcc_0[0],ValAcc_0_5[0])):\n    print(\"epoches: {:}, TrainingLoss:{:}, EvalLoss: {:}, Accuracy: {:}, AccuracyTrue: {:}, Accuracy+-0.5: {:}\".format(i,round(float(x),6),round(float(y),4),round(float(z),4),round(float(a),4),round(float(b),4)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = 0\nfor trainingLoss in TrainingLoss[-1]:\n    plt.plot(list(range(epoches)), trainingLoss)\n    t+= trainingLoss[-1]\nprint(t/len(TrainingLoss))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = 0\nfor valLoss in ValLoss:\n    plt.plot(list(range(epoches)), valLoss)\n    t+= valLoss[-1]\nprint(t/len(TrainingLoss))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#t = 0\n#for aucs in ValAuc:\n#    plt.plot(list(range(epoches)), aucs)\n#    t+= aucs[-1]\n#print(t/len(ValAuc))\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = 0\nfor accs in ValAcc:\n    plt.plot(list(range(epoches)), accs)\n    t+= accs[-1]\nprint(t/len(ValAcc))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}